{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embargos de Declaracao.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBazvY0iDekfjeG2GXJ2AL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaoSouza2121/Embargos-Declaracao/blob/main/Embargos_de_Declaracao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGqHi6CTuDLT"
      },
      "source": [
        "##Inteligência Artificial para Previsão de Sentenças em Embargos de Declaração"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHwEaQMittCB"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfPZZz6tvKo3"
      },
      "source": [
        "##Preparando os Dados\n",
        "O texto abaixo é um exemplo de embargo de declaração. Embora o texto represente um embargo, dados críticos foram substituídos por informações genéricas, o que não compromete o objetivo do estudo de caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6irdsl2MvDMF"
      },
      "source": [
        "# Texto de embargo de declaração\n",
        "embargo = \"\"\"O embargante sofreu o ajuizamento de ação de danos morais e materiais, cujo objeto é o reaver os\n",
        "valores pagos pelo sinal dado em um contrato de compra e venda de imóvel no qual não foi dado continuidade. Em 24\n",
        "de fevereiro de 2012, o Magistrado proferiu decisão de fls. 277 a 280, que condenou todas as demandadas\n",
        "solidariamente no seguinte teor: Diante de todo o exposto, com fundamento no art. 1234, I, do CPC/2015,\n",
        "julgo procedentes em parte os pedidos constantes na inicial, condenando solidariamente as demandadas, XPTO LTDA,\n",
        "BOB CAMARGO DE MORAES, a Pagarema título de indenização por danos morais, consoante fundamentação acima discorrida,\n",
        "o montante de R$ 1.500,00 (um mil e quinhentos reais), corrigidos monetariamente pelo INPC desde a data\n",
        "desta decisão, acrescidos de juros de 1% ao mês, a partir da citação; condeno ainda, à restituição do valor\n",
        "pago pelo demandante como sinal da entrada do imóvel, descontando apenas 20% (vinte por cento), referente às\n",
        "despesas, devendo incidir juros de 1% (um por cento) ao mês contados da citação e correção monetária pelo INPC a\n",
        "partir da sentença. Contudo, data venia, houve omissão e obscuridade na referida decisão, haja vista que a omissão\n",
        "se deu pela ausência dos julgamentos das preliminares (Necessidade de Perícia Técnica e a incompetência de\n",
        "Juizado Especial) proposta posteriormente em aditamento de contestação (Fls 251 a 254) para impugnar áudios\n",
        "juntados pelo embargado, autorizado a ser realizada pela Douta Magistrada em audiência de Conciliação,\n",
        "instrução e julgamento de fls 235 e 236, por ausência de intimação anterior para realizar a já tratada\n",
        "impugnação aos áudios anexados.\"\"\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkmugOSNw-ps"
      },
      "source": [
        "# Limpeza do texto substituindo vírgulas e pontos por espaços e colocando as palavras em minúsculo\n",
        "embargo = embargo.replace(',','').replace('.','').lower().split()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT25YoInxDRs"
      },
      "source": [
        "# Criação do corpus com o texto acima\n",
        "corpus = set(embargo)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqIJj5K4xRhp",
        "outputId": "e181fa1f-42f1-4b6a-c627-bee93ffba873"
      },
      "source": [
        "# Visualiza o corpus\n",
        "corpus"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(fls',\n",
              " '(necessidade',\n",
              " '(um',\n",
              " '(vinte',\n",
              " '1%',\n",
              " '1234',\n",
              " '150000',\n",
              " '20%',\n",
              " '2012',\n",
              " '235',\n",
              " '236',\n",
              " '24',\n",
              " '251',\n",
              " '254)',\n",
              " '277',\n",
              " '280',\n",
              " 'a',\n",
              " 'acima',\n",
              " 'acrescidos',\n",
              " 'aditamento',\n",
              " 'ainda',\n",
              " 'ajuizamento',\n",
              " 'anexados',\n",
              " 'anterior',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'apenas',\n",
              " 'art',\n",
              " 'as',\n",
              " 'audiência',\n",
              " 'ausência',\n",
              " 'autorizado',\n",
              " 'ação',\n",
              " 'bob',\n",
              " 'camargo',\n",
              " 'cento)',\n",
              " 'citação',\n",
              " 'citação;',\n",
              " 'com',\n",
              " 'como',\n",
              " 'compra',\n",
              " 'conciliação',\n",
              " 'condenando',\n",
              " 'condeno',\n",
              " 'condenou',\n",
              " 'consoante',\n",
              " 'constantes',\n",
              " 'contados',\n",
              " 'contestação',\n",
              " 'continuidade',\n",
              " 'contrato',\n",
              " 'contudo',\n",
              " 'correção',\n",
              " 'corrigidos',\n",
              " 'cpc/2015',\n",
              " 'cujo',\n",
              " 'da',\n",
              " 'dado',\n",
              " 'danos',\n",
              " 'das',\n",
              " 'data',\n",
              " 'de',\n",
              " 'decisão',\n",
              " 'demandadas',\n",
              " 'demandante',\n",
              " 'descontando',\n",
              " 'desde',\n",
              " 'despesas',\n",
              " 'desta',\n",
              " 'deu',\n",
              " 'devendo',\n",
              " 'diante',\n",
              " 'discorrida',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'douta',\n",
              " 'e',\n",
              " 'em',\n",
              " 'embargado',\n",
              " 'embargante',\n",
              " 'entrada',\n",
              " 'especial)',\n",
              " 'exposto',\n",
              " 'fevereiro',\n",
              " 'fls',\n",
              " 'foi',\n",
              " 'fundamentação',\n",
              " 'fundamento',\n",
              " 'haja',\n",
              " 'houve',\n",
              " 'i',\n",
              " 'impugnar',\n",
              " 'impugnação',\n",
              " 'imóvel',\n",
              " 'incidir',\n",
              " 'incompetência',\n",
              " 'indenização',\n",
              " 'inicial',\n",
              " 'inpc',\n",
              " 'instrução',\n",
              " 'intimação',\n",
              " 'juizado',\n",
              " 'julgamento',\n",
              " 'julgamentos',\n",
              " 'julgo',\n",
              " 'juntados',\n",
              " 'juros',\n",
              " 'já',\n",
              " 'ltda',\n",
              " 'magistrada',\n",
              " 'magistrado',\n",
              " 'materiais',\n",
              " 'mil',\n",
              " 'monetariamente',\n",
              " 'monetária',\n",
              " 'montante',\n",
              " 'moraes',\n",
              " 'morais',\n",
              " 'mês',\n",
              " 'na',\n",
              " 'no',\n",
              " 'não',\n",
              " 'o',\n",
              " 'objeto',\n",
              " 'obscuridade',\n",
              " 'omissão',\n",
              " 'os',\n",
              " 'pagarema',\n",
              " 'pago',\n",
              " 'pagos',\n",
              " 'para',\n",
              " 'parte',\n",
              " 'partir',\n",
              " 'pedidos',\n",
              " 'pela',\n",
              " 'pelo',\n",
              " 'perícia',\n",
              " 'por',\n",
              " 'posteriormente',\n",
              " 'preliminares',\n",
              " 'procedentes',\n",
              " 'proferiu',\n",
              " 'proposta',\n",
              " 'qual',\n",
              " 'que',\n",
              " 'quinhentos',\n",
              " 'r$',\n",
              " 'reais)',\n",
              " 'realizada',\n",
              " 'realizar',\n",
              " 'reaver',\n",
              " 'referente',\n",
              " 'referida',\n",
              " 'restituição',\n",
              " 'se',\n",
              " 'seguinte',\n",
              " 'sentença',\n",
              " 'ser',\n",
              " 'sinal',\n",
              " 'sofreu',\n",
              " 'solidariamente',\n",
              " 'teor:',\n",
              " 'todas',\n",
              " 'todo',\n",
              " 'tratada',\n",
              " 'técnica',\n",
              " 'título',\n",
              " 'um',\n",
              " 'valor',\n",
              " 'valores',\n",
              " 'venda',\n",
              " 'venia',\n",
              " 'vista',\n",
              " 'xpto',\n",
              " 'à',\n",
              " 'às',\n",
              " 'áudios',\n",
              " 'é'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq337G0ZxbjZ"
      },
      "source": [
        "# Comprimento do corpus\n",
        "corpus_length = len(corpus)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKlwbo9NzeOj"
      },
      "source": [
        "# Dicionários para TF-IDF\n",
        "dic_palavra = {}\n",
        "dic_inverso_palavra = {}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvoTHpIX0Z0L"
      },
      "source": [
        "# Loop pelo corpus para criar os dicionários\n",
        "for i, palavra in enumerate(corpus):\n",
        "    dic_palavra[palavra] = i\n",
        "    dic_inverso_palavra[i] = palavra"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPUn0epp0fSm"
      },
      "source": [
        "# Lista para receber os dados\n",
        "dados = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjbyhmhp0mBg"
      },
      "source": [
        "# Loop pelo texto par extrair sentenças e palavras\n",
        "for i in range(2, len(embargo) - 2):\n",
        "    sentence = [embargo[i-2], embargo[i-1], embargo[i+1], embargo[i+2]]\n",
        "    target = embargo[i]\n",
        "    dados.append((sentence, target))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jll1AlQ087Y"
      },
      "source": [
        "sentence = [embargo[i-2], embargo[i-1], embargo[i+1], embargo[i+2]]\n",
        "\n",
        "Para uma palavra no índice i, obtemos duas palavras antes e duas palavras depois. A palavra no índice i será o nosso target e a sentença será composta das duas palavras e duas palavras depois da palavra target.\n",
        "\n",
        "Após treinar o modelo, seremos capazes de prever cada palavra com base nas palavras a sua volta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N1hI_SL072m",
        "outputId": "a695e7e0-f7ff-40cf-8a14-ea32e8c1a9b0"
      },
      "source": [
        "# Visualizado os dados\n",
        "print(dados[3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['o', 'ajuizamento', 'ação', 'de'], 'de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfkk6U1Q1Xb4"
      },
      "source": [
        "As quatro palavras na lista serão os dados de entrada e a palavra fora da lista, sera a variavel de saida.('de' nesse caso)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DueNX6-P1qfF"
      },
      "source": [
        "# Construção do Modelo CBoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2wxjZ_R1QZe"
      },
      "source": [
        "# definindo o comprimento de cada embedding\n",
        "embedding_length = 20"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24pOpBqU198K"
      },
      "source": [
        "# Classe para o modelo\n",
        "class CBoW(torch.nn.Module):\n",
        "\n",
        "    # Método construtor\n",
        "    def __init__(self, corpus_length, embedding_dim):\n",
        "        super(CBoW, self).__init__()\n",
        "       \n",
        "        # Camada de entrada do modelo para criação da embedding\n",
        "        self.embeddings = nn.Embedding(corpus_length, embedding_dim)\n",
        "\n",
        "        # Camadas lineares\n",
        "        self.linear1 = nn.Linear(embedding_dim, 64)\n",
        "        self.linear2 = nn.Linear(64, corpus_length)\n",
        "       \n",
        "        # Camadas de ativação\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "    # Passo (forward)\n",
        "    def forward(self, inputs):\n",
        "       \n",
        "        # Aqui definimos a ordem ds camadas da rede neural\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    # Obtém a word_emdedding\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.LongTensor([dic_palavra[word]])\n",
        "        return self.embeddings(word).view(1,-1)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9e3_8az3Deu"
      },
      "source": [
        "# Cria o modelo CBoW\n",
        "modelo = CBoW(corpus_length, embedding_length)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aarzJNGW3JdM"
      },
      "source": [
        "# Função de custo\n",
        "loss_function = nn.NLLLoss()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2aru5Dp3NeL"
      },
      "source": [
        "# Otimizador do modelo (backpropagation)\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.01)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTwPhtH3Rri"
      },
      "source": [
        "# Função para criar o vetor de sentenças, necessário para treinar o modelo\n",
        "def make_sentence_vector(sentence, word_dict):\n",
        "    idxs = [word_dict[w] for w in sentence]\n",
        "    return torch.tensor(idxs, dtype = torch.long)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqUQ0RVV3Xz7",
        "outputId": "d6963ec0-3553-4f16-e203-d14719751374"
      },
      "source": [
        "# Dicionario de palavras\n",
        "dic_palavra"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(fls': 176,\n",
              " '(necessidade': 152,\n",
              " '(um': 147,\n",
              " '(vinte': 102,\n",
              " '1%': 12,\n",
              " '1234': 53,\n",
              " '150000': 93,\n",
              " '20%': 155,\n",
              " '2012': 42,\n",
              " '235': 37,\n",
              " '236': 134,\n",
              " '24': 92,\n",
              " '251': 57,\n",
              " '254)': 61,\n",
              " '277': 26,\n",
              " '280': 31,\n",
              " 'a': 27,\n",
              " 'acima': 25,\n",
              " 'acrescidos': 100,\n",
              " 'aditamento': 98,\n",
              " 'ainda': 124,\n",
              " 'ajuizamento': 141,\n",
              " 'anexados': 80,\n",
              " 'anterior': 97,\n",
              " 'ao': 87,\n",
              " 'aos': 71,\n",
              " 'apenas': 16,\n",
              " 'art': 6,\n",
              " 'as': 172,\n",
              " 'audiência': 175,\n",
              " 'ausência': 107,\n",
              " 'autorizado': 66,\n",
              " 'ação': 10,\n",
              " 'bob': 11,\n",
              " 'camargo': 43,\n",
              " 'cento)': 131,\n",
              " 'citação': 30,\n",
              " 'citação;': 59,\n",
              " 'com': 112,\n",
              " 'como': 106,\n",
              " 'compra': 32,\n",
              " 'conciliação': 151,\n",
              " 'condenando': 127,\n",
              " 'condeno': 39,\n",
              " 'condenou': 85,\n",
              " 'consoante': 99,\n",
              " 'constantes': 49,\n",
              " 'contados': 126,\n",
              " 'contestação': 156,\n",
              " 'continuidade': 19,\n",
              " 'contrato': 69,\n",
              " 'contudo': 165,\n",
              " 'correção': 84,\n",
              " 'corrigidos': 89,\n",
              " 'cpc/2015': 9,\n",
              " 'cujo': 36,\n",
              " 'da': 164,\n",
              " 'dado': 74,\n",
              " 'danos': 20,\n",
              " 'das': 153,\n",
              " 'data': 154,\n",
              " 'de': 46,\n",
              " 'decisão': 75,\n",
              " 'demandadas': 104,\n",
              " 'demandante': 48,\n",
              " 'descontando': 79,\n",
              " 'desde': 1,\n",
              " 'despesas': 115,\n",
              " 'desta': 47,\n",
              " 'deu': 169,\n",
              " 'devendo': 168,\n",
              " 'diante': 162,\n",
              " 'discorrida': 34,\n",
              " 'do': 73,\n",
              " 'dos': 120,\n",
              " 'douta': 108,\n",
              " 'e': 129,\n",
              " 'em': 65,\n",
              " 'embargado': 3,\n",
              " 'embargante': 33,\n",
              " 'entrada': 17,\n",
              " 'especial)': 105,\n",
              " 'exposto': 52,\n",
              " 'fevereiro': 121,\n",
              " 'fls': 177,\n",
              " 'foi': 24,\n",
              " 'fundamentação': 21,\n",
              " 'fundamento': 150,\n",
              " 'haja': 158,\n",
              " 'houve': 174,\n",
              " 'i': 45,\n",
              " 'impugnar': 117,\n",
              " 'impugnação': 5,\n",
              " 'imóvel': 166,\n",
              " 'incidir': 109,\n",
              " 'incompetência': 15,\n",
              " 'indenização': 146,\n",
              " 'inicial': 88,\n",
              " 'inpc': 139,\n",
              " 'instrução': 95,\n",
              " 'intimação': 54,\n",
              " 'juizado': 113,\n",
              " 'julgamento': 122,\n",
              " 'julgamentos': 171,\n",
              " 'julgo': 170,\n",
              " 'juntados': 2,\n",
              " 'juros': 103,\n",
              " 'já': 70,\n",
              " 'ltda': 0,\n",
              " 'magistrada': 13,\n",
              " 'magistrado': 51,\n",
              " 'materiais': 50,\n",
              " 'mil': 68,\n",
              " 'monetariamente': 118,\n",
              " 'monetária': 63,\n",
              " 'montante': 28,\n",
              " 'moraes': 94,\n",
              " 'morais': 44,\n",
              " 'mês': 163,\n",
              " 'na': 161,\n",
              " 'no': 29,\n",
              " 'não': 145,\n",
              " 'o': 55,\n",
              " 'objeto': 110,\n",
              " 'obscuridade': 137,\n",
              " 'omissão': 60,\n",
              " 'os': 96,\n",
              " 'pagarema': 91,\n",
              " 'pago': 132,\n",
              " 'pagos': 41,\n",
              " 'para': 136,\n",
              " 'parte': 76,\n",
              " 'partir': 23,\n",
              " 'pedidos': 35,\n",
              " 'pela': 101,\n",
              " 'pelo': 81,\n",
              " 'perícia': 138,\n",
              " 'por': 148,\n",
              " 'posteriormente': 72,\n",
              " 'preliminares': 64,\n",
              " 'procedentes': 125,\n",
              " 'proferiu': 18,\n",
              " 'proposta': 142,\n",
              " 'qual': 159,\n",
              " 'que': 56,\n",
              " 'quinhentos': 62,\n",
              " 'r$': 82,\n",
              " 'reais)': 22,\n",
              " 'realizada': 116,\n",
              " 'realizar': 67,\n",
              " 'reaver': 83,\n",
              " 'referente': 7,\n",
              " 'referida': 8,\n",
              " 'restituição': 78,\n",
              " 'se': 160,\n",
              " 'seguinte': 140,\n",
              " 'sentença': 77,\n",
              " 'ser': 123,\n",
              " 'sinal': 144,\n",
              " 'sofreu': 86,\n",
              " 'solidariamente': 40,\n",
              " 'teor:': 14,\n",
              " 'todas': 130,\n",
              " 'todo': 90,\n",
              " 'tratada': 4,\n",
              " 'técnica': 167,\n",
              " 'título': 143,\n",
              " 'um': 173,\n",
              " 'valor': 114,\n",
              " 'valores': 149,\n",
              " 'venda': 58,\n",
              " 'venia': 133,\n",
              " 'vista': 119,\n",
              " 'xpto': 135,\n",
              " 'à': 157,\n",
              " 'às': 111,\n",
              " 'áudios': 128,\n",
              " 'é': 38}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-zJsfWW3ere",
        "outputId": "23ab8604-3c8c-41c9-e2d3-12270db92d28"
      },
      "source": [
        "# O dicionário de palavras será convertido em um vetor de sentenças. Aqui um exemplo:\n",
        "print(make_sentence_vector(['pela','ausência','dos','julgamentos'], dic_palavra))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([101, 107, 120, 171])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrmWJ0IM35mD"
      },
      "source": [
        "##Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhbOYUNz32nd",
        "outputId": "a1499a46-9839-4b96-db35-0f15804052a4"
      },
      "source": [
        "# Loop por 150 passadas (epochs) de treinamento\n",
        "for epoch in range(150):\n",
        "   \n",
        "    # Inicia o erro da época com 0\n",
        "    epoch_loss = 0\n",
        "   \n",
        "    # Loop pelos dados de entrada (sentence) e saída (target)\n",
        "    for sentence, target in dados:\n",
        "       \n",
        "        # Inicializa os gradientes com zero\n",
        "        modelo.zero_grad()\n",
        "       \n",
        "        # Cria o vetor de sentença com os dados de entrada (que devem estar no dicionário de palavras)\n",
        "        sentence_vector = make_sentence_vector(sentence, dic_palavra)  \n",
        "       \n",
        "        # Usa o vetor para fazer previsões com o modelo e retorna as probabilidades\n",
        "        log_probs = modelo(sentence_vector)\n",
        "       \n",
        "        # Calcula o erro do modelo\n",
        "        loss = loss_function(log_probs, torch.tensor([dic_palavra[target]], dtype = torch.long))\n",
        "       \n",
        "        # Chama o método de backpropagation para calcular o gradiente da derivada\n",
        "        loss.backward()\n",
        "       \n",
        "        # Otimiza os pesos do modelo e segue para a próxima passada\n",
        "        # É aqui que o aprendizado acontece\n",
        "        optimizer.step()\n",
        "       \n",
        "        # Atualiza o erro da época\n",
        "        epoch_loss += loss.data\n",
        "       \n",
        "    # Imprime epoch e erro da epoch    \n",
        "    print('Epoch: ' + str(epoch) + ', Erro do Modelo: ' + str(epoch_loss.item()))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Erro do Modelo: 1355.1697998046875\n",
            "Epoch: 1, Erro do Modelo: 1234.663818359375\n",
            "Epoch: 2, Erro do Modelo: 1141.6375732421875\n",
            "Epoch: 3, Erro do Modelo: 1049.6793212890625\n",
            "Epoch: 4, Erro do Modelo: 952.3583374023438\n",
            "Epoch: 5, Erro do Modelo: 847.2706909179688\n",
            "Epoch: 6, Erro do Modelo: 736.2577514648438\n",
            "Epoch: 7, Erro do Modelo: 622.0828247070312\n",
            "Epoch: 8, Erro do Modelo: 510.283447265625\n",
            "Epoch: 9, Erro do Modelo: 406.8824768066406\n",
            "Epoch: 10, Erro do Modelo: 316.377197265625\n",
            "Epoch: 11, Erro do Modelo: 241.63351440429688\n",
            "Epoch: 12, Erro do Modelo: 183.13949584960938\n",
            "Epoch: 13, Erro do Modelo: 139.2725372314453\n",
            "Epoch: 14, Erro do Modelo: 106.71981811523438\n",
            "Epoch: 15, Erro do Modelo: 83.20346069335938\n",
            "Epoch: 16, Erro do Modelo: 65.71538543701172\n",
            "Epoch: 17, Erro do Modelo: 52.82475662231445\n",
            "Epoch: 18, Erro do Modelo: 43.15243148803711\n",
            "Epoch: 19, Erro do Modelo: 35.98662185668945\n",
            "Epoch: 20, Erro do Modelo: 30.576839447021484\n",
            "Epoch: 21, Erro do Modelo: 26.408767700195312\n",
            "Epoch: 22, Erro do Modelo: 23.189794540405273\n",
            "Epoch: 23, Erro do Modelo: 20.589704513549805\n",
            "Epoch: 24, Erro do Modelo: 18.488805770874023\n",
            "Epoch: 25, Erro do Modelo: 16.764307022094727\n",
            "Epoch: 26, Erro do Modelo: 15.307289123535156\n",
            "Epoch: 27, Erro do Modelo: 14.076545715332031\n",
            "Epoch: 28, Erro do Modelo: 13.016949653625488\n",
            "Epoch: 29, Erro do Modelo: 12.102052688598633\n",
            "Epoch: 30, Erro do Modelo: 11.299417495727539\n",
            "Epoch: 31, Erro do Modelo: 10.590298652648926\n",
            "Epoch: 32, Erro do Modelo: 9.962974548339844\n",
            "Epoch: 33, Erro do Modelo: 9.402544975280762\n",
            "Epoch: 34, Erro do Modelo: 8.897741317749023\n",
            "Epoch: 35, Erro do Modelo: 8.441370010375977\n",
            "Epoch: 36, Erro do Modelo: 8.031435012817383\n",
            "Epoch: 37, Erro do Modelo: 7.652207851409912\n",
            "Epoch: 38, Erro do Modelo: 7.30840539932251\n",
            "Epoch: 39, Erro do Modelo: 6.991738319396973\n",
            "Epoch: 40, Erro do Modelo: 6.700729846954346\n",
            "Epoch: 41, Erro do Modelo: 6.430604457855225\n",
            "Epoch: 42, Erro do Modelo: 6.181634426116943\n",
            "Epoch: 43, Erro do Modelo: 5.94940185546875\n",
            "Epoch: 44, Erro do Modelo: 5.734308242797852\n",
            "Epoch: 45, Erro do Modelo: 5.531798362731934\n",
            "Epoch: 46, Erro do Modelo: 5.3433051109313965\n",
            "Epoch: 47, Erro do Modelo: 5.16642427444458\n",
            "Epoch: 48, Erro do Modelo: 5.000420093536377\n",
            "Epoch: 49, Erro do Modelo: 4.843760013580322\n",
            "Epoch: 50, Erro do Modelo: 4.696779727935791\n",
            "Epoch: 51, Erro do Modelo: 4.5572428703308105\n",
            "Epoch: 52, Erro do Modelo: 4.426381587982178\n",
            "Epoch: 53, Erro do Modelo: 4.301398754119873\n",
            "Epoch: 54, Erro do Modelo: 4.182841777801514\n",
            "Epoch: 55, Erro do Modelo: 4.071369171142578\n",
            "Epoch: 56, Erro do Modelo: 3.964387893676758\n",
            "Epoch: 57, Erro do Modelo: 3.863053321838379\n",
            "Epoch: 58, Erro do Modelo: 3.766446828842163\n",
            "Epoch: 59, Erro do Modelo: 3.6742711067199707\n",
            "Epoch: 60, Erro do Modelo: 3.586073160171509\n",
            "Epoch: 61, Erro do Modelo: 3.501967668533325\n",
            "Epoch: 62, Erro do Modelo: 3.4216344356536865\n",
            "Epoch: 63, Erro do Modelo: 3.3444249629974365\n",
            "Epoch: 64, Erro do Modelo: 3.270528793334961\n",
            "Epoch: 65, Erro do Modelo: 3.199810028076172\n",
            "Epoch: 66, Erro do Modelo: 3.131774663925171\n",
            "Epoch: 67, Erro do Modelo: 3.066326379776001\n",
            "Epoch: 68, Erro do Modelo: 3.003567934036255\n",
            "Epoch: 69, Erro do Modelo: 2.9432084560394287\n",
            "Epoch: 70, Erro do Modelo: 2.8849570751190186\n",
            "Epoch: 71, Erro do Modelo: 2.828956365585327\n",
            "Epoch: 72, Erro do Modelo: 2.7748653888702393\n",
            "Epoch: 73, Erro do Modelo: 2.722938060760498\n",
            "Epoch: 74, Erro do Modelo: 2.6724298000335693\n",
            "Epoch: 75, Erro do Modelo: 2.6238996982574463\n",
            "Epoch: 76, Erro do Modelo: 2.577033042907715\n",
            "Epoch: 77, Erro do Modelo: 2.53161883354187\n",
            "Epoch: 78, Erro do Modelo: 2.4876482486724854\n",
            "Epoch: 79, Erro do Modelo: 2.4452836513519287\n",
            "Epoch: 80, Erro do Modelo: 2.4040448665618896\n",
            "Epoch: 81, Erro do Modelo: 2.3642191886901855\n",
            "Epoch: 82, Erro do Modelo: 2.3256001472473145\n",
            "Epoch: 83, Erro do Modelo: 2.2880842685699463\n",
            "Epoch: 84, Erro do Modelo: 2.2518887519836426\n",
            "Epoch: 85, Erro do Modelo: 2.2165424823760986\n",
            "Epoch: 86, Erro do Modelo: 2.1823318004608154\n",
            "Epoch: 87, Erro do Modelo: 2.1490731239318848\n",
            "Epoch: 88, Erro do Modelo: 2.1167399883270264\n",
            "Epoch: 89, Erro do Modelo: 2.085350513458252\n",
            "Epoch: 90, Erro do Modelo: 2.0547845363616943\n",
            "Epoch: 91, Erro do Modelo: 2.0250141620635986\n",
            "Epoch: 92, Erro do Modelo: 1.9961341619491577\n",
            "Epoch: 93, Erro do Modelo: 1.968044638633728\n",
            "Epoch: 94, Erro do Modelo: 1.940513253211975\n",
            "Epoch: 95, Erro do Modelo: 1.9139032363891602\n",
            "Epoch: 96, Erro do Modelo: 1.8878507614135742\n",
            "Epoch: 97, Erro do Modelo: 1.8624932765960693\n",
            "Epoch: 98, Erro do Modelo: 1.8377776145935059\n",
            "Epoch: 99, Erro do Modelo: 1.813637137413025\n",
            "Epoch: 100, Erro do Modelo: 1.7900699377059937\n",
            "Epoch: 101, Erro do Modelo: 1.7672039270401\n",
            "Epoch: 102, Erro do Modelo: 1.7447870969772339\n",
            "Epoch: 103, Erro do Modelo: 1.7228846549987793\n",
            "Epoch: 104, Erro do Modelo: 1.7015496492385864\n",
            "Epoch: 105, Erro do Modelo: 1.6807156801223755\n",
            "Epoch: 106, Erro do Modelo: 1.6602381467819214\n",
            "Epoch: 107, Erro do Modelo: 1.6403285264968872\n",
            "Epoch: 108, Erro do Modelo: 1.6208629608154297\n",
            "Epoch: 109, Erro do Modelo: 1.6018035411834717\n",
            "Epoch: 110, Erro do Modelo: 1.5831419229507446\n",
            "Epoch: 111, Erro do Modelo: 1.5648622512817383\n",
            "Epoch: 112, Erro do Modelo: 1.5471065044403076\n",
            "Epoch: 113, Erro do Modelo: 1.529563546180725\n",
            "Epoch: 114, Erro do Modelo: 1.5125032663345337\n",
            "Epoch: 115, Erro do Modelo: 1.4957994222640991\n",
            "Epoch: 116, Erro do Modelo: 1.4793802499771118\n",
            "Epoch: 117, Erro do Modelo: 1.4633522033691406\n",
            "Epoch: 118, Erro do Modelo: 1.447529673576355\n",
            "Epoch: 119, Erro do Modelo: 1.4322198629379272\n",
            "Epoch: 120, Erro do Modelo: 1.417011022567749\n",
            "Epoch: 121, Erro do Modelo: 1.4022639989852905\n",
            "Epoch: 122, Erro do Modelo: 1.387711763381958\n",
            "Epoch: 123, Erro do Modelo: 1.373478651046753\n",
            "Epoch: 124, Erro do Modelo: 1.3594834804534912\n",
            "Epoch: 125, Erro do Modelo: 1.3457542657852173\n",
            "Epoch: 126, Erro do Modelo: 1.3323476314544678\n",
            "Epoch: 127, Erro do Modelo: 1.3191434144973755\n",
            "Epoch: 128, Erro do Modelo: 1.3061883449554443\n",
            "Epoch: 129, Erro do Modelo: 1.293423056602478\n",
            "Epoch: 130, Erro do Modelo: 1.2809414863586426\n",
            "Epoch: 131, Erro do Modelo: 1.2687163352966309\n",
            "Epoch: 132, Erro do Modelo: 1.2566391229629517\n",
            "Epoch: 133, Erro do Modelo: 1.244824767112732\n",
            "Epoch: 134, Erro do Modelo: 1.2331873178482056\n",
            "Epoch: 135, Erro do Modelo: 1.2217973470687866\n",
            "Epoch: 136, Erro do Modelo: 1.2105762958526611\n",
            "Epoch: 137, Erro do Modelo: 1.1994917392730713\n",
            "Epoch: 138, Erro do Modelo: 1.1886976957321167\n",
            "Epoch: 139, Erro do Modelo: 1.1780239343643188\n",
            "Epoch: 140, Erro do Modelo: 1.1675429344177246\n",
            "Epoch: 141, Erro do Modelo: 1.157271385192871\n",
            "Epoch: 142, Erro do Modelo: 1.1471188068389893\n",
            "Epoch: 143, Erro do Modelo: 1.1371475458145142\n",
            "Epoch: 144, Erro do Modelo: 1.1273384094238281\n",
            "Epoch: 145, Erro do Modelo: 1.117685079574585\n",
            "Epoch: 146, Erro do Modelo: 1.108206868171692\n",
            "Epoch: 147, Erro do Modelo: 1.09884774684906\n",
            "Epoch: 148, Erro do Modelo: 1.0896658897399902\n",
            "Epoch: 149, Erro do Modelo: 1.0806187391281128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJhZTbZd5KLB"
      },
      "source": [
        "O Erro foi reduzido a cada passada do aprendizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcZHzljA5TUH"
      },
      "source": [
        "# Previsão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8taUNo94NdE"
      },
      "source": [
        "# Função para obter uma previsão\n",
        "def get_resultado_previsto(input, dic_inverso_palavra):\n",
        "    index = np.argmax(input)\n",
        "    return dic_inverso_palavra[index]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMaVRwoz5xBf"
      },
      "source": [
        "# Função para prever sentenças (aplicamos aos novos dados o mesmo tratamento usado nos dados de treino)\n",
        "def preve_sentenca(sentence):\n",
        "   \n",
        "    # Dividimos a sentença com split\n",
        "    sentence_split = sentence.replace('.','').lower().split()\n",
        "   \n",
        "    # Criamos o vetor de sentença\n",
        "    sentence_vector = make_sentence_vector(sentence_split, dic_palavra)\n",
        "   \n",
        "    # Faz a previsão com o modelo\n",
        "    prediction_array = modelo(sentence_vector).data.numpy()\n",
        "   \n",
        "    # Print dos resultados\n",
        "    print('Palavras Anteriores: {}\\n'.format(sentence_split[:2]))\n",
        "    print('Palavra Prevista: {}\\n'.format(get_resultado_previsto(prediction_array[0], dic_inverso_palavra)))\n",
        "    print('Palavras Seguintes: {}\\n'.format(sentence_split[2:]))\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68rigdVi6Ild"
      },
      "source": [
        "##Previsões com o Modelo\n",
        "Dentro da frase: \"ausência de intimação anterior para realizar\", vejamos se o modelo consegue prever a palavra.\n",
        "\n",
        "Vou omitir a palavra intimação e essa deve ser a palavra prevista pelo modelo. Vamos passar como dados de entrada as duas palavras anteriores e as duas palavras posteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfG8n6zW53zt",
        "outputId": "fae9c84a-7581-4439-995b-1c0eda9daaaa"
      },
      "source": [
        "preve_sentenca('ausência de anterior para')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palavras Anteriores: ['ausência', 'de']\n",
            "\n",
            "Palavra Prevista: intimação\n",
            "\n",
            "Palavras Seguintes: ['anterior', 'para']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-S2wRlz6Syx",
        "outputId": "7b1159bf-7741-43e0-bfd0-1f77d64cea42"
      },
      "source": [
        "# Embedding da palavra\n",
        "print(modelo.get_word_emdedding('intimação'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5104, -0.0242, -2.1160,  0.2460,  0.1927, -0.3201, -0.2984, -0.2386,\n",
            "         -1.0195, -1.2949, -1.5453,  0.0362, -0.2132, -1.3972,  0.3941, -0.1989,\n",
            "          0.3803, -0.4413, -0.2238, -0.6779]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmuc0OKN6pOF",
        "outputId": "1115156e-43a2-41b0-e9b9-98d612d55cf8"
      },
      "source": [
        "# Previsão com o modelo\n",
        "preve_sentenca('devendo incidir de 1%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palavras Anteriores: ['devendo', 'incidir']\n",
            "\n",
            "Palavra Prevista: juros\n",
            "\n",
            "Palavras Seguintes: ['de', '1%']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKpaRcn97XZs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}